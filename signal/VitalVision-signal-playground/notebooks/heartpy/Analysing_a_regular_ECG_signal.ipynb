{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing a regular ECG signal\n",
    "\n",
    "In this notebook I'll show you three examples of using HeartPy to analyse good-to-reasonable quality ECG signals you may encounter.\n",
    "\n",
    "We'll be looking at three excerpts from the [European ST-T Database over at Physionet](https://physionet.org/content/edb/1.0.0/). There are all recorded at 250 Hz"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:27:38.582002Z",
     "start_time": "2024-05-09T09:27:37.882211Z"
    }
   },
   "source": [
    "#import packages\n",
    "import heartpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_rate = 250"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first file and visualise it:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:27:38.878485Z",
     "start_time": "2024-05-09T09:27:38.583598Z"
    }
   },
   "source": [
    "data = hp.get_data('e0103.csv')\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data)\n",
    "plt.show()"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a very nice and clean signal. We don't need to do any preprocessing and can run analysis right away:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#run analysis\n",
    "wd, m = hp.process(data, sample_rate)\n",
    "\n",
    "#visualise in plot of custom size\n",
    "plt.figure(figsize=(12,4))\n",
    "hp.plotter(wd, m)\n",
    "\n",
    "#display computed measures\n",
    "for measure in m.keys():\n",
    "    print('%s: %f' %(measure, m[measure]))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### That went well. \n",
    "\n",
    "Now let's move on to the next one and see if we can analyse that one too:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data = hp.get_data('e0110.csv')\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data)\n",
    "plt.show()\n",
    "\n",
    "#and zoom in a bit\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data[0:2500])\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ah!\n",
    "\n",
    "We have an issue where the T-wave (the broad wave right after the main QRS complex) is present. We can filter this using a notch filter, as we're interested in the QRS comples.\n",
    "\n",
    "What the notch filter does is apply a frequency filter to a very narrow frequency range, allowing us to get rid of some things without disturbing the QRS complexes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "filtered = hp.filter_signal(data, cutoff = 0.05, sample_rate = sample_rate, filtertype='notch')\n",
    "\n",
    "#visualize again\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(filtered)\n",
    "plt.show()\n",
    "\n",
    "#and zoom in a bit\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data[0:2500], label = 'original signal')\n",
    "plt.plot(filtered[0:2500], alpha=0.5, label = 'filtered signal')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We've now reduced the amplitude of the T-wave and are ready for analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#run analysis\n",
    "wd, m = hp.process(hp.scale_data(filtered), sample_rate)\n",
    "\n",
    "#visualise in plot of custom size\n",
    "plt.figure(figsize=(12,4))\n",
    "hp.plotter(wd, m)\n",
    "\n",
    "#display computed measures\n",
    "for measure in m.keys():\n",
    "    print('%s: %f' %(measure, m[measure]))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oh dear\n",
    "\n",
    "HeartPy is distrusting some peaks. This is because HeartPy's optimizer likes broader peaks than some ECG recordings provide (especially lower sampling rates). Usually when filtering the peak width decreases as well, potentially causing issues. \n",
    "\n",
    "The solution is simple. We can upsample the signal using [scipy.signal.resample](https://docs.scipy.org/doc/scipy-0.16.0/reference/generated/scipy.signal.resample.html) to help with this!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from scipy.signal import resample\n",
    "\n",
    "#resample the data. Usually 2, 4, or 6 times is enough depending on original sampling rate\n",
    "resampled_data = resample(filtered, len(filtered) * 2)\n",
    "\n",
    "#And run the analysis again. Don't forget to up the sample rate as well!\n",
    "wd, m = hp.process(hp.scale_data(resampled_data), sample_rate * 2)\n",
    "\n",
    "#visualise in plot of custom size\n",
    "plt.figure(figsize=(12,4))\n",
    "hp.plotter(wd, m)\n",
    "\n",
    "#display computed measures\n",
    "for measure in m.keys():\n",
    "    print('%s: %f' %(measure, m[measure]))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling the signal has enabled HeartPy to optimize and find the position for all peaks in the signal.\n",
    "\n",
    "Note the use of ***hp.scale_data()*** in the processing function. This is recommended when the amplitude is low (2.4-3.8 in the original data).\n",
    "\n",
    "------------\n",
    "\n",
    "Let's look at the last example"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data = hp.get_data('e0124.csv')\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data)\n",
    "plt.show()\n",
    "\n",
    "#and zoom in a bit\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data[0:2500])\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we have a very strong signal present in the recording. That is always nice to see. Analysis again is then straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#run analysis\n",
    "wd, m = hp.process(hp.scale_data(data), sample_rate)\n",
    "\n",
    "#visualise in plot of custom size\n",
    "plt.figure(figsize=(12,4))\n",
    "hp.plotter(wd, m)\n",
    "\n",
    "#display computed measures\n",
    "for measure in m.keys():\n",
    "    print('%s: %f' %(measure, m[measure]))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And again we can fix the 'mistrusted' peaks with modest upsampling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#resample the data. Usually 2, 4, or 6 times is enough depending on original sampling rate\n",
    "resampled_data = resample(data, len(filtered) * 2)\n",
    "\n",
    "#And run the analysis again. Don't forget to up the sample rate as well!\n",
    "wd, m = hp.process(hp.scale_data(resampled_data), sample_rate * 2)\n",
    "\n",
    "#visualise in plot of custom size\n",
    "plt.figure(figsize=(12,4))\n",
    "hp.plotter(wd, m)\n",
    "\n",
    "#display computed measures\n",
    "for measure in m.keys():\n",
    "    print('%s: %f' %(measure, m[measure]))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since 1.2.4 HeartPy includes Poincar√© nonlinear methods too\n",
    "\n",
    "Use them like the plotter function:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "hp.plot_poincare(wd, m)\n",
    "\n",
    "#print poincare measures\n",
    "poincare_measures = ['sd1', 'sd2', 's', 'sd1/sd2']\n",
    "print('\\nnonlinear poincare measures:')\n",
    "for measure in poincare_measures:\n",
    "    print('%s: %f' %(measure, m[measure]))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's it!\n",
    "\n",
    "I hope this notebook has given you an overview of how to analyse good to medium quality ECG data. \n",
    "\n",
    "There's also a more advanced notebook available on the repository on [how to handle poor quality ECG data](https://github.com/paulvangentcom/heartrate_analysis_python/blob/master/examples/5_noisy_ECG/Analysing_Noisy_ECG.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
